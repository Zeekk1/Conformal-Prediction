{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b93b0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchcp.classification.score import APS, RAPS\n",
    "from torchcp.classification.predictor import SplitPredictor\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2fa841",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the model\n",
    "def create_advanced_model(num_classes):\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    in_features = model.fc.in_features\n",
    "    \n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Dropout(0.3),\n",
    "        nn.Linear(in_features, 512),\n",
    "        nn.BatchNorm1d(512),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(512, num_classes)\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9caaee32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\dissertation\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\anaconda3\\envs\\dissertation\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Loading the trained and saved model\n",
    "model = create_advanced_model(num_classes=3)\n",
    "model.load_state_dict(torch.load(\"best_covid_model.pth\"))\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee58d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoaders recreated successfully!\n"
     ]
    }
   ],
   "source": [
    "# Copying the same script from the training file to avoid errors during import\n",
    "import os\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "BASE_PATH = r\"C:\\Users\\User\\Desktop\\Dissertation\\Code\\dataset2\\COVID-19_Radiography_Dataset\"\n",
    "COVID_PATH = r\"C:\\Users\\User\\Desktop\\Dissertation\\Code\\dataset2\\COVID-19_Radiography_Dataset\\COVID\\images\"\n",
    "NORMAL_PATH= r\"C:\\Users\\User\\Desktop\\Dissertation\\Code\\dataset2\\COVID-19_Radiography_Dataset\\Normal\\images\"\n",
    "VIRAL_PNEUMONIA_PATH=r\"C:\\Users\\User\\Desktop\\Dissertation\\Code\\dataset2\\COVID-19_Radiography_Dataset\\Viral Pneumonia\\images\"\n",
    "\n",
    "\n",
    "def load_image_paths():\n",
    "    covid_images = glob(os.path.join(COVID_PATH, \"*.png\")) \n",
    "    normal_images = glob(os.path.join(NORMAL_PATH, \"*.png\"))\n",
    "    viral_pneumonia_images = glob(os.path.join(VIRAL_PNEUMONIA_PATH, \"*.png\"))\n",
    "    return covid_images, normal_images, viral_pneumonia_images\n",
    "\n",
    "def get_eval_transform():\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.Grayscale(num_output_channels=3),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "class CovidDataset(Dataset):\n",
    "    def __init__(self, df, transform, class_roots):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "        self.class_roots = class_roots\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        label = int(row['label'])\n",
    "        img_name = row['Image Index']\n",
    "        \n",
    "        img_path = os.path.join(self.class_roots[label], img_name)\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        img = self.transform(img)\n",
    "        \n",
    "        return img, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "def paths_to_df(paths, labels):\n",
    "    return pd.DataFrame({\n",
    "        'Image Index': [Path(p).name for p in paths],\n",
    "        'label': labels\n",
    "    })\n",
    "\n",
    "covid_paths, normal_paths, viral_pneumonia_paths = load_image_paths()\n",
    "\n",
    "normal_labels = [0] * len(normal_paths)\n",
    "covid_labels = [1] * len(covid_paths)\n",
    "viral_pneumonia_labels = [2] * len(viral_pneumonia_paths)\n",
    "\n",
    "all_images = normal_paths + covid_paths + viral_pneumonia_paths\n",
    "all_labels = normal_labels + covid_labels + viral_pneumonia_labels\n",
    "\n",
    "\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    all_images, all_labels, test_size=0.25, random_state=42, stratify=all_labels)\n",
    "\n",
    "X_train, X_cal, y_train, y_cal = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.333, random_state=42, stratify=y_temp)\n",
    "\n",
    "eval_transform = get_eval_transform()\n",
    "\n",
    "\n",
    "\n",
    "class_roots = {\n",
    "    0: os.path.join(BASE_PATH, \"Normal\", \"images\"),\n",
    "    1: os.path.join(BASE_PATH, \"COVID\", \"images\"),\n",
    "    2: os.path.join(BASE_PATH, \"Viral Pneumonia\", \"images\")\n",
    "}\n",
    "\n",
    "# Create datasets and loaders\n",
    "cal_df = paths_to_df(X_cal, y_cal)\n",
    "test_df = paths_to_df(X_test, y_test)\n",
    "\n",
    "cal_dataset = CovidDataset(cal_df, eval_transform, class_roots)\n",
    "test_dataset = CovidDataset(test_df, eval_transform, class_roots)\n",
    "\n",
    "cal_loader = DataLoader(cal_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95d0e2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model, dataloader):\n",
    "    model.eval()\n",
    "    all_logits = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(dataloader, desc=\"Getting predictions\"):\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            all_logits.append(outputs.cpu())\n",
    "            all_labels.append(labels)\n",
    "    \n",
    "    return torch.cat(all_logits), torch.cat(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1429ed4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting predictions: 100%|██████████| 119/119 [08:50<00:00,  4.46s/it]\n",
      "Getting predictions: 100%|██████████| 119/119 [08:22<00:00,  4.23s/it]\n"
     ]
    }
   ],
   "source": [
    "#Extracting and saving the predicitions\n",
    "cal_logits, cal_labels = get_predictions(model, cal_loader)\n",
    "test_logits, test_labels = get_predictions(model, test_loader)\n",
    "\n",
    "\n",
    "torch.save({\n",
    "    'cal_logits': cal_logits, 'cal_labels': cal_labels,\n",
    "    'test_logits': test_logits, 'test_labels': test_labels\n",
    "}, 'covid_model_logits.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee59eb75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded predictions - Cal: torch.Size([3785, 3]), Test: torch.Size([3789, 3])\n"
     ]
    }
   ],
   "source": [
    "# Loading the saved logits\n",
    "data = torch.load('covid_model_logits.pt')\n",
    "cal_logits = data['cal_logits']\n",
    "cal_labels = data['cal_labels']\n",
    "test_logits = data['test_logits']\n",
    "test_labels = data['test_labels']\n",
    "\n",
    "print(f\"Loaded predictions - Cal: {cal_logits.shape}, Test: {test_logits.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b129e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up APS conformal predictor...\n"
     ]
    }
   ],
   "source": [
    "# Conformal prediction with APS\n",
    "from torchcp.classification.score import APS\n",
    "from torchcp.classification.predictor import SplitPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409f73b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== APS Results ===\n",
      "Average set size: 0.95\n",
      "Coverage: 0.899\n"
     ]
    }
   ],
   "source": [
    "# Create APS predictor\n",
    "aps_score = APS(score_type=\"softmax\", randomized=True)\n",
    "aps_predictor = SplitPredictor(score_function=aps_score)\n",
    "\n",
    "# Calculate threshold with calibration logits\n",
    "aps_predictor.calculate_threshold(cal_logits, cal_labels, alpha=0.1)\n",
    "\n",
    "# Generate prediction sets for test data\n",
    "aps_prediction_sets = aps_predictor.predict_with_logits(test_logits)\n",
    "\n",
    "# Show results\n",
    "print(\"=== APS Results ===\")\n",
    "print(f\"Average set size: {aps_prediction_sets.sum(dim=1).float().mean():.2f}\")\n",
    "print(f\"Coverage: {aps_prediction_sets[range(len(test_labels)), test_labels].float().mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19418f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RAPS Results ===\n",
      "Average set size: 0.93\n",
      "Coverage: 0.906\n"
     ]
    }
   ],
   "source": [
    "raps_score = RAPS(score_type=\"softmax\", randomized=True, penalty=5, kreg=1)\n",
    "raps_predictor = SplitPredictor(score_function=raps_score)\n",
    "\n",
    "\n",
    "raps_predictor.calculate_threshold(cal_logits, cal_labels, alpha=0.1)\n",
    "\n",
    "\n",
    "raps_prediction_sets = raps_predictor.predict_with_logits(test_logits)\n",
    "\n",
    "\n",
    "print(\"=== RAPS Results ===\")\n",
    "print(f\"Average set size: {raps_prediction_sets.sum(dim=1).float().mean():.2f}\")\n",
    "print(f\"Coverage: {raps_prediction_sets[range(len(test_labels)), test_labels].float().mean():.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58613d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RAPS Parameter Tuning ===\n",
      "Penalty | kreg | Set Size | Coverage\n",
      "----------------------------------------\n",
      "  0.01  |  0   |  0.951   |  0.901\n",
      "  0.01  |  1   |  0.941   |  0.895\n",
      "  0.01  |  2   |  0.947   |  0.898\n",
      "  0.05  |  0   |  0.954   |  0.912\n",
      "  0.05  |  1   |  0.947   |  0.906\n",
      "  0.05  |  2   |  0.951   |  0.904\n",
      "  0.10  |  0   |  0.940   |  0.905\n",
      "  0.10  |  1   |  0.934   |  0.899\n",
      "  0.10  |  2   |  0.944   |  0.896\n",
      "  0.20  |  0   |  0.928   |  0.898\n",
      "  0.20  |  1   |  0.927   |  0.897\n",
      "  0.20  |  2   |  0.946   |  0.897\n",
      "  1.00  |  0   |  0.926   |  0.901\n",
      "  1.00  |  1   |  0.933   |  0.907\n",
      "  1.00  |  2   |  0.944   |  0.895\n",
      "  5.00  |  0   |  0.921   |  0.897\n",
      "  5.00  |  1   |  0.921   |  0.896\n",
      "  5.00  |  2   |  0.952   |  0.899\n"
     ]
    }
   ],
   "source": [
    "# Try different RAPS parameters for even better results\n",
    "print(\"=== RAPS Parameter Tuning ===\")\n",
    "print(\"Penalty | kreg | Set Size | Coverage\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for penalty in [0.01, 0.05, 0.1, 0.2,1,5]:\n",
    "   for kreg in [0, 1, 2]:\n",
    "       raps_score = RAPS(score_type=\"softmax\", randomized=True, penalty=penalty, kreg=kreg)\n",
    "       raps_predictor = SplitPredictor(score_function=raps_score)\n",
    "       \n",
    "       # Calculating the threshold and predict\n",
    "       raps_predictor.calculate_threshold(cal_logits, cal_labels, alpha=0.1)\n",
    "       prediction_sets = raps_predictor.predict_with_logits(test_logits)\n",
    "       \n",
    "       # Metric calculation\n",
    "       avg_set_size = prediction_sets.sum(dim=1).float().mean().item()\n",
    "       coverage = prediction_sets[range(len(test_labels)), test_labels].float().mean().item()\n",
    "       \n",
    "       print(f\"  {penalty:4.2f}  |  {kreg}   |  {avg_set_size:.3f}   |  {coverage:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1cc3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Comparison ===\n",
      "APS  - Set size: 0.96, Coverage: 0.912\n",
      "RAPS - Set size: 0.93, Coverage: 0.904\n"
     ]
    }
   ],
   "source": [
    "# Comparing both the methods \n",
    "print(\"\\n=== Comparison ===\")\n",
    "print(f\"APS  - Set size: {aps_prediction_sets.sum(dim=1).float().mean():.2f}, Coverage: {aps_prediction_sets[range(len(test_labels)), test_labels].float().mean():.3f}\")\n",
    "#print(f\"RAPS - Set size: {raps_prediction_sets.sum(dim=1).float().mean():.2f}, Coverage: {raps_prediction_sets[range(len(test_labels)), test_labels].float().mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132435a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dissertation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
